{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxYASTXBDVc3"
      },
      "source": [
        "# CS 189 Neural Networks Homework\n",
        "**Note:** before starting this notebook, please save a copy of it to your own google drive, or your changes will not persist.\n",
        "\n",
        "This part of the assignment is designed to get you familiar with how engineers in the real world train neural network systems. It isn't designed to be difficult. In fact, everything you need to complete the assignment is available directly on the pytorch website [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html). This note book will have the following components:\n",
        "\n",
        "1. Understanding the basics of Pytorch (no deliverables)\n",
        "2. Training a simple neural network on FasionMNIST (Deliverable = training graphs)\n",
        "3. Training a convolutional neural network on CIFAR-10 (Deliverable = training graphs, explanation of methods and CSV file)\n",
        "\n",
        "You will also get practice being an ML engineer, by reading documentation and using it to implement models. The first section of this notebook will cover an outline of what you need to know -- we are confident that you can find the rest on your own.\n",
        "\n",
        "You just need to complete the deliverables and turn in your code. If you want to run this notebook locally on your own GPUs, make sure to appropriately install pytorch on your system. If you don't want to use pytorch and instead want to experiment with Tensorflow, feel free, but you may still need to install pytorch to download the datasets. Moreover, our staff has more familiarity with pytorch, and may be unable to assist you in case you run into any errors with tensorflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5qoJVI0RCyaH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\WIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Imports for pytorch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import tqdm.notebook as tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-GpmsVIEYLn"
      },
      "source": [
        "# 1. Understanding Pytorch\n",
        "\n",
        "Pytorch is based on the \"autograd\" paradigm. Essentially, you perform operations on multi-dimensional arrays like in numpy, except pytorch will automatically handle gradient tracking. In this section you will understand how to use pytorch.\n",
        "\n",
        "This section should help you understand the full pipeline of creating and training a model in pytorch. Feel free to re-use code from this section in the assigned tasks.\n",
        "\n",
        "Content in this section closely follows this pytorch tutorial: https://pytorch.org/tutorials/beginner/basics/intro.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgaXYlojE5Pm"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "Tensors can be created from numpy data or by using pytorch directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6iKkuKmnFNvP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor from np: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]], dtype=torch.int32) \n",
            "\n",
            "Rand Tensor: \n",
            " tensor([[0.7271, 0.2382, 0.6328],\n",
            "        [0.0688, 0.5569, 0.5842]]) \n",
            "\n",
            "Rand Numpy Array: \n",
            " [[0.7270982  0.23821461 0.6328015 ]\n",
            " [0.06881005 0.55691314 0.5841822 ]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "\n",
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "np_rand_array = rand_tensor.numpy()\n",
        "\n",
        "print(f\"Tensor from np: \\n {x_np} \\n\")\n",
        "print(f\"Rand Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Rand Numpy Array: \\n {np_rand_array} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEeXQUJqFk0k"
      },
      "source": [
        "They also support slicing and math operations very similar to numpy. See the examples below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zIGbRiM-FfCx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Sum as a tensor: tensor(64.) , Sum as an item: 64.0\n"
          ]
        }
      ],
      "source": [
        "# Slicing\n",
        "tensor = torch.ones(4, 4)\n",
        "print('First row: ',tensor[0])\n",
        "print('First column: ', tensor[:, 0])\n",
        "\n",
        "# Matrix Operations\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "# Getting a single item\n",
        "scalar = torch.sum(y1) # sums all elements\n",
        "item = scalar.item()\n",
        "print(\"Sum as a tensor:\", scalar, \", Sum as an item:\", item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0fscsOfH3dz"
      },
      "source": [
        "## Autograd\n",
        "This small section shows you how pytorch computes gradients. When we create tensors, we can set `requires_grad` to be true to indicate that we are using gradients. For most of the work that you actually do, you will use the `nn` package, which automatically sets all parameter tensors to have `requires_grad=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X1btdxFJIvz_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W gradient: tensor([[0.9696],\n",
            "        [0.9696],\n",
            "        [0.9696],\n",
            "        [0.9696],\n",
            "        [0.9696]])\n",
            "b gradient: tensor([0.9696])\n",
            "Weight before tensor([[ 0.0850],\n",
            "        [ 0.3123],\n",
            "        [ 1.8430],\n",
            "        [ 1.3564],\n",
            "        [-0.3523]], requires_grad=True)\n",
            "Updated weight tensor([[-0.0119],\n",
            "        [ 0.2154],\n",
            "        [ 1.7460],\n",
            "        [ 1.2595],\n",
            "        [-0.4492]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Below is an example of computing the gradient for a single data point in logistic regression using pytorch's autograd.\n",
        "\n",
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(1) # label\n",
        "w = torch.randn(5, 1, requires_grad=True)\n",
        "b = torch.randn(1, requires_grad=True)\n",
        "pred = torch.sigmoid(torch.matmul(x, w) + b)\n",
        "loss = torch.nn.functional.binary_cross_entropy(pred, y)\n",
        "loss.backward() # Computers gradients\n",
        "print(\"W gradient:\", w.grad)\n",
        "print(\"b gradient:\", b.grad)\n",
        "\n",
        "# when we want to actually take an update step, we can use optimizers:\n",
        "optimizer = torch.optim.SGD([w, b], lr=0.1)\n",
        "print(\"Weight before\", w)\n",
        "optimizer.step() # use the computed gradients to update\n",
        "# Print updated weights\n",
        "print(\"Updated weight\", w)\n",
        "\n",
        "# Performing operations with gradients enabled is slow...\n",
        "# You can disable gradient computation using the following enclosure:\n",
        "with torch.no_grad():\n",
        "    # Perform operations without gradients\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9WqzZdGf-J"
      },
      "source": [
        "## Devices\n",
        "Pytorch supports accelerating computation using GPUs which are available on google colab. To use a GPU on google colab, go to runtime -> change runtime type -> select GPU.\n",
        "\n",
        "Note that there is some level of strategy for knowing when to use which runtime type. Colab will kick users off of GPU for a certain period of time if you use it too much. Thus, its best to run simple models and prototype to get everything working on CPU, then switch the instance type over to GPU for training runs and parameter tuning.\n",
        "\n",
        "Its best practice to make sure your code works on any device (GPU or CPU) for pytorch, but note that numpy operations can only run on the CPU. Here is a standard flow for using GPU acceleration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LwHYcdpmG0Tq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cpu\n"
          ]
        }
      ],
      "source": [
        "# Determine the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device\", device)\n",
        "# Next create your tensors\n",
        "tensor = torch.zeros(4, 4, requires_grad=True)\n",
        "# Move the tensor to the device you want to use\n",
        "tensor = tensor.to(device)\n",
        "\n",
        "# Perform whatever operations you want.... (often this will involve gradients)\n",
        "# These operations will be accelerated by GPU.\n",
        "tensor = 10*(tensor + 1)\n",
        "\n",
        "# bring the tensor back to CPU, first detaching it from any gradient computations\n",
        "tensor = tensor.detach().cpu()\n",
        "\n",
        "tensor_np = tensor.numpy() # Convert to numpy if you want to perform numpy operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZvRtdC1NZFe"
      },
      "source": [
        "## The NN Package\n",
        "Pytorch implements composable blocks in `Module` classes. All layers and modules in pytorch inherit from `nn.Module`. When you make a module you need to implement two functions: `__init__(self, *args, **kwargs)` and `foward(self, *args, **kwargs)`. Modules also have some nice helper functions, namely `parameters` which will recursively return all of the parameters. Here is an example of a logistic regression model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rNvfGFz4OTp_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters [Parameter containing:\n",
            "tensor([[-0.1553, -0.1068, -0.0842, -0.0112, -0.0592, -0.2751,  0.2681,  0.3039,\n",
            "         -0.2049,  0.3112]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0766], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "class Perceptron(nn.Module):\n",
        "  def __init__(self, in_dim):\n",
        "    super().__init__()\n",
        "    self.layer = nn.Linear(in_dim, 1) # This is a linear layer, it computes Xw + b\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.sigmoid(self.layer(x)).squeeze(-1)\n",
        "\n",
        "perceptron = Perceptron(10)\n",
        "perceptron = perceptron.to(device) # Move all the perceptron's tensors to the device\n",
        "print(\"Parameters\", list(perceptron.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHV9D362PE0w"
      },
      "source": [
        "## Datasets\n",
        "\n",
        "Pytorch has nice interfaces for using datasets. Suppose we create a logistic regression dataset as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G7VBsu23Pj9w"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "c1_x1, c1_x2 = np.random.multivariate_normal([-2.5,3], [[1, 0.3],[0.3, 1]], 100).T\n",
        "c2_x1, c2_x2 = np.random.multivariate_normal([1,1], [[2, 1],[1, 2]], 100).T\n",
        "c1_X = np.vstack((c1_x1, c1_x2)).T\n",
        "c2_X = np.vstack((c2_x1, c2_x2)).T\n",
        "train_X = np.concatenate((c1_X, c2_X))\n",
        "train_y = np.concatenate((np.zeros(100), np.ones(100)))\n",
        "# Shuffle the data\n",
        "permutation = np.random.permutation(train_X.shape[0])\n",
        "train_X = train_X[permutation, :]\n",
        "train_y = train_y[permutation]\n",
        "# Plot the data\n",
        "plt.plot(c1_x1, c1_x2, 'x')\n",
        "plt.plot(c2_x1, c2_x2, 'o')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ0_Dch3P4Cd"
      },
      "source": [
        "We can then create a pytorch dataset object as follows. Often times, the default pytorch datasets will create these objects for you. Then, we can apply dataloaders to iterate over the dataset in batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gFUJJdgdPsht"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch x: tensor([[-1.1950,  3.5342],\n",
            "        [ 4.7282,  1.9255],\n",
            "        [ 0.5452,  0.0931],\n",
            "        [ 2.0991,  1.8913],\n",
            "        [-3.8055,  2.0266],\n",
            "        [-0.4026,  1.1671],\n",
            "        [ 2.5309,  0.6365],\n",
            "        [-0.1306,  2.8031],\n",
            "        [-1.6373, -1.5993],\n",
            "        [ 0.3218, -0.3553]], dtype=torch.float64)\n",
            "Batch y: tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))\n",
        "# We can create a dataloader that iterates over the dataset in batches.\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "for x, y in dataloader:\n",
        "    print(\"Batch x:\", x)\n",
        "    print(\"Batch y:\", y)\n",
        "    break\n",
        "\n",
        "# Clean up the dataloader as we make a new one later\n",
        "del dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vaq5wwPQtNO"
      },
      "source": [
        "## Training Loop Example\n",
        "Here is an example of training a full logistic regression model in pytorch. Note the extensive use of modules -- modules can be used for storing networks, computation steps etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1WwjYScvQms3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cpu\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     16\u001b[0m     training_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     18\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \u001b[38;5;66;03m# Remove the gradients from the previous step\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\WIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\notebook.py:233\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    232\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\WIN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
            "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device\", device)\n",
        "\n",
        "epochs = 10\n",
        "batch_size = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "num_features = dataset[0][0].shape[0]\n",
        "model = Perceptron(num_features).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = torch.nn.BCELoss()\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model.train() # Put model in training mode\n",
        "for epoch in range(epochs):\n",
        "    training_losses = []\n",
        "    for x, y in tqdm.tqdm(dataloader, unit=\"batch\"):\n",
        "        x, y = x.float().to(device), y.float().to(device)\n",
        "        optimizer.zero_grad() # Remove the gradients from the previous step\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        training_losses.append(loss.item())\n",
        "    print(\"Finished Epoch\", epoch + 1, \", training loss:\", np.mean(training_losses))\n",
        "\n",
        "# We can run predictions on the data to determine the final accuracy.\n",
        "with torch.no_grad():\n",
        "    model.eval() # Put model in eval mode\n",
        "    num_correct = 0\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.float().to(device), y.float().to(device)\n",
        "        pred = model(x)\n",
        "        num_correct += torch.sum(torch.round(pred) == y).item()\n",
        "    print(\"Final Accuracy:\", num_correct / len(dataset))\n",
        "    model.train() # Put model back in train mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOxM8vT4SsD9"
      },
      "source": [
        "# Task 1: MLP For FashionMNIST\n",
        "Now you will train a multi-layer perceptron model on the FashionMNIST dataset. Your deliverables are as follows:\n",
        "\n",
        "1. Code for training an MLP on FashionMNIST.\n",
        "2. A plot of the training and validation loss for at least 8 epochs.\n",
        "3. A plot of the training and validation accuracy for each epoch, achieving a final validation accuracy of at least 82% by the end of the training.\n",
        "\n",
        "Below we will create the training and validation datasets for you. It is on you to implement an MLP / Feed Forward neural network yourself. Please leverage the example training loop from above.\n",
        "\n",
        "Here are some pytorch components that you should definitely use:\n",
        "1. `nn.Linear`\n",
        "2. Some activation: `nn.ReLU`, `nn.Tanh`, `nn.Sigmoid`, etc.\n",
        "3. `nn.CrossEntropyLoss`\n",
        "\n",
        "Here are some challenges that you will need to overcome:\n",
        "1. The data is, by default, configured in image form, i.e. a (28 x 28) tensor per sample, instead of single feature vector. You will need to reshape it somewhere to feed it in as vector to the MLP. There are many ways of doing this.\n",
        "2. You need to write code for plotting.\n",
        "3. You need to find the appropriate hyper-parameters to achieve good accuracy.\n",
        "\n",
        "Your underlying model must be fully connected or \"dense\", and may not use any convolutions etc., but you can use anything in `torch.optim` or any layers in `torch.nn` besides `nn.Linear` that do not have weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sSW4B4yR-G2"
      },
      "outputs": [],
      "source": [
        "# Creating the datasets\n",
        "transform = torchvision.transforms.ToTensor() # feel free to modify this as you see fit.\n",
        "\n",
        "training_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "validation_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDToJ1LN1lDt"
      },
      "source": [
        "Before training a neural network, let's visualize our data first! Running the cell below will display the first 9 images in a 3 by 3 grid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My5OkEFv1u06"
      },
      "outputs": [],
      "source": [
        "images = [training_data[i][0] for i in range(9)]\n",
        "plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=3, padding=5).numpy().transpose((1, 2, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4PPZnVCXH8_"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2qHmtqRUYHz"
      },
      "source": [
        "# Task 2: CNNs for CIFAR-10\n",
        "\n",
        "In this section, you will create a CNN for the CIFAR dataset, and submit your predictions to the autograder. It is recommended that you use GPU acceleration for this part.\n",
        "\n",
        "Here are some of the components you should consider using:\n",
        "1. `nn.Conv2d`\n",
        "2. `nn.ReLU`\n",
        "3. `nn.Linear`\n",
        "4. `nn.CrossEntropyLoss`\n",
        "5. `nn.MaxPooling2d` (though many implementations without it exist)\n",
        "\n",
        "We encourage you to explore different ways of improving your model to obtain higher accuracies. Here are some suggestions for things to look into:\n",
        "1. Popular CNN architectures like ResNets, etc.\n",
        "2. Different optimizers and their parameters (see `torch.optim`)\n",
        "3. Image preprocessing / data augmentation (see `torchvision.transforms`)\n",
        "4. Regularization or dropout (see `torch.optim` and `torch.nn` respectively)\n",
        "5. Learning rate scheduling: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
        "6. Weight initialization: https://pytorch.org/docs/stable/nn.init.html\n",
        "\n",
        "Though we encourage you to explore, there are some rules:\n",
        "1. You are not allowed to install or use packages not included by default in the Colab Environment.\n",
        "2. You are not allowed to use any pre-defined architectures or feature extractors in your network.\n",
        "3. You are not allowed to use **any** pretrained weights, i.e. no transfer learning.\n",
        "4. You cannot train on the test data (that would pretty much defeat the whole point of machine learning).\n",
        "\n",
        "Otherwise everything is fair game!\n",
        "\n",
        "Your deliverables are as follows:\n",
        "1. Code for training a CNN on CIFAR-10.\n",
        "2. Provide at least (1) training curve for your model, depicting loss per epoch or step after training for at least 8 epochs.\n",
        "3. Explain the components of your final model, and how you think your design choices contributed to it's performance.\n",
        "\n",
        "After you train your model, we have included skeleton code that should be used to generate the predictions that will be submitted to the Autograder. **You must follow the instructions below under the submission header**. Note that if you apply any processing or transformations to the data, you will need to do the same to the test data, otherwise you will likely achieve very low accuracy.\n",
        "\n",
        "It is expected that this task will take a while to train. Our very simple solution achieves a training accuracy of 90.2% and a test accuracy of 74.8% after 10 epochs (be careful of overfitting!). That said, it is possible to achieve 95% or higher test accuracy on CIFAR 10 with a good model design and some hyperparameter tuning. For this assignment, your model should achieve an accuracy above 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmwd_kzNT-Cq"
      },
      "outputs": [],
      "source": [
        "# Creating the datasets, feel free to change this as long as you do the same to the test data.\n",
        "# You can also modify this to split the data into training and validation.\n",
        "# See https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split\n",
        "\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "# If you make a train-test partition it is up to you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY7rDFcg3og6"
      },
      "source": [
        "Again, let's first visualize our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PNE-4LT3lx8"
      },
      "outputs": [],
      "source": [
        "images = [training_data[i][0] for i in range(9)]\n",
        "plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=3, padding=5).numpy().transpose((1, 2, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4DyQNjKjlol"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNPuqiPEs8QI"
      },
      "source": [
        "### Autograder Submission\n",
        "The following code is for you to make your submission to the gradescope autograder. Here are the steps you must follow:\n",
        "\n",
        "1. Upload `cifar10_test_data_fa23.npy` to the colab notebook by going to files on the right hand pane, then hitting \"upload\".\n",
        "2. Run the following cell to generate the dataset object for the test data. Feel free to modify the code to use the same transforms that you use for the training data. By default, this will re-use the `transform` variable.\n",
        "3. In the second cell, write code to run predictions on the testing dataset and store them into an array called `predictions`.\n",
        "4. Run the final cell which will convert your predictions array into a CSV file.\n",
        "5. Go to the files pane again, and download the file called `submission.csv` by clicking the three dots and then download.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzC5hCcZlBoF"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CIFAR10Test(torchvision.datasets.VisionDataset):\n",
        "\n",
        "    def __init__(self, transform=None, target_transform=None):\n",
        "        super(CIFAR10Test, self).__init__(None, transform=transform,\n",
        "                                      target_transform=target_transform)\n",
        "        assert os.path.exists(\"cifar10_test_data_fa23.npy\"), \"You must upload the test data to the file system.\"\n",
        "        self.data = [np.load(\"cifar10_test_data_fa23.npy\", allow_pickle=False)]\n",
        "\n",
        "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
        "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        img = self.data[index]\n",
        "        img = Image.fromarray(img)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "# Create the test dataset\n",
        "testing_data = CIFAR10Test(\n",
        "    transform=transform, # NOTE: Make sure transform is the same as the one used in the training dataset.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzXwbAetsF4v"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Recommendation: create a `test_dataloader` from torch.utils.data.DataLoader with `shuffle=False` to iterate over the test data in batches.\n",
        "\n",
        "# Store a numpy vector of the predictions for the test set in the variable `predictions`.\n",
        "predictions = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NilUcXbjsuy5"
      },
      "outputs": [],
      "source": [
        "# This code below will generate the predictions.csv file.\n",
        "import pandas as pd\n",
        "\n",
        "if isinstance(predictions, np.ndarray):\n",
        "    predictions = predictions.astype(int)\n",
        "else:\n",
        "    predictions = np.array(predictions, dtype=int)\n",
        "assert predictions.shape == (len(testing_data),), \"Predictions were not the correct shape\"\n",
        "df = pd.DataFrame({'Category': predictions})\n",
        "df.index += 1  # Ensures that the index starts at 1.\n",
        "df.to_csv('predictions.csv', index_label='Id')\n",
        "\n",
        "# Now download the predictions.csv file to submit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofNTv8Z57x1w"
      },
      "source": [
        "Congrats! You made it to the end."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
